{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training a model in AML\n",
    "1. step up an azure machine learning workspace\n",
    "2. prepare your data: gather and preprocess your data\n",
    "3. define your compute environment: options include AML compute, azure databricks and azure virtual machines\n",
    "4. choose your model type: based on your problem doman and data. it can be a classification, regression, clustering model or any type\n",
    "5. write your training script: it include loading the data, defining the model architecture, training the model and evaluating its perfomance\n",
    "6. create an experiment: they are used to track the training process and results. create an experiment to log metrics, outputs and other relevant information during model training\n",
    "7. Run your script training script: submit your training script to the choosen  compute environment to start training process.\n",
    "8. monitor training progress: you can track metrics, view logs and troubleshoot any issue that may arise.\n",
    "9. evaluate your model: evaluate your model using validation of data or other techniques. model testing makes it easy to deploy and manage your model in production environments.\n",
    "10. Deploy your trained model as a web service or container to make predictions on new data.\n",
    "11. Monitor and maintain your deployed model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. set up AZML workspace.\n",
    "2.prepare data and write a script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 1.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "# load the data \n",
    "iris_df = pd.read_csv(\"https://raw.githubusercontent.com/uiuc-cse/data-fa14/gh-pages/data/iris.csv\")\n",
    "# split the data into features and target\n",
    "X = iris_df.drop('species', axis=1)\n",
    "y = iris_df['species']\n",
    "# split ,the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "#train a random forest classifier\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "#evaluate the model\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('accuracy', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "step 3. Define the compute environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Workspace\n",
    "from azureml.core.compute import AmlCompute, ComputeTarget\n",
    "\n",
    "# Load workspace\n",
    "workspace = Workspace.from_config()\n",
    "\n",
    "# Define Azure Machine Learning Compute\n",
    "compute_name = \"cpu-cluster\"\n",
    "compute_config = AmlCompute.provisioning_configuration(vm_size=\"STANDARD_DS2_V2\", max_nodes=4)\n",
    "compute_target = ComputeTarget.create(workspace, compute_name, compute_config)\n",
    "compute_target.wait_for_completion(show_output=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "step 4: create an experiment and run training script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'azureml.core.workspace' has no attribute 'service_context'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#create an experiment\u001b[39;00m\n\u001b[0;32m      3\u001b[0m experiment_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miris_classification\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 4\u001b[0m experiment \u001b[38;5;241m=\u001b[39m Experiment(workspace, experiment_name)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m#create a script run configuration\u001b[39;00m\n\u001b[0;32m      7\u001b[0m src \u001b[38;5;241m=\u001b[39m ScriptRunConfig(source_directory\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, script\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain.py\u001b[39m\u001b[38;5;124m\"\u001b[39m, compute_target\u001b[38;5;241m=\u001b[39mcompute_target)\n",
      "File \u001b[1;32mc:\\Users\\10734341\\anaconda3\\Lib\\site-packages\\azureml\\core\\experiment.py:124\u001b[0m, in \u001b[0;36mExperiment.__init__\u001b[1;34m(self, workspace, name, _skip_name_validation, _id, _archived_time, _create_in_cloud, _experiment_dto, **kwargs)\u001b[0m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_workspace \u001b[38;5;241m=\u001b[39m workspace\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name \u001b[38;5;241m=\u001b[39m name\n\u001b[1;32m--> 124\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_workspace_client \u001b[38;5;241m=\u001b[39m WorkspaceClient(workspace\u001b[38;5;241m.\u001b[39mservice_context)\n\u001b[0;32m    126\u001b[0m _ident \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_ident\u001b[39m\u001b[38;5;124m\"\u001b[39m, ChainedIdentity\u001b[38;5;241m.\u001b[39mDELIM\u001b[38;5;241m.\u001b[39mjoin([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name]))\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _skip_name_validation:\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'azureml.core.workspace' has no attribute 'service_context'"
     ]
    }
   ],
   "source": [
    "from azureml.core import Experiment, ScriptRunConfig\n",
    "#create an experiment\n",
    "experiment_name = \"iris_classification\"\n",
    "experiment = Experiment(workspace, experiment_name)\n",
    "\n",
    "#create a script run configuration\n",
    "src = ScriptRunConfig(source_directory=\".\", script=\"train.py\", compute_target=compute_target)\n",
    "\n",
    "#submit the experiment\n",
    "run = experiment.submit(src)\n",
    "run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "step 5: register the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'run' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miris-classifier\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      4\u001b[0m model_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs/model.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 5\u001b[0m model \u001b[38;5;241m=\u001b[39m run\u001b[38;5;241m.\u001b[39mregister_model(model_name\u001b[38;5;241m=\u001b[39mmodel_name, model_path\u001b[38;5;241m=\u001b[39mmodel_path)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'run' is not defined"
     ]
    }
   ],
   "source": [
    "from azureml.core import Model\n",
    "#register the model\n",
    "model_name = \"iris-classifier\"\n",
    "model_path = \"outputs/model.pkl\"\n",
    "model = run.register_model(model_name=model_name, model_path=model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "step 6: deploy the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Environment, Model\n",
    "from azureml.core.model import InferenceConfig\n",
    "from azureml.core.model import InferenceConfig\n",
    "\n",
    "#define environment\n",
    "env = Environment.from_conda_specification(name=\"sklearn-env\", file_path=\"Environment.yml\")\n",
    "#define inference configuration\n",
    "inference_config = InferenceConfig(entry_script=\"score.py\", environment=env)\n",
    "\n",
    "#deploy model as a web service\n",
    "\n",
    "service_name = \"iris-classifier-service\"\n",
    "deployment_config = AciWebservice.deploy_configuration"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
